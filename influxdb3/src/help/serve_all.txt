Run the InfluxDB 3 Core server

Examples:
  # Run with local file storage:
  1. influxdb3 serve --node-id node1 --object-store file --data-dir ~/.influxdb_data
  2. influxdb3 create token --admin
  3. Write and query with unhashed token

  # Run with AWS S3:
  1. influxdb3 serve --node-id node1 --object-store s3 --bucket influxdb-data \
    --aws-access-key-id KEY --aws-secret-access-key SECRET
  2. influxdb3 create token --admin
  3. Write and query with unhashed token

{} [OPTIONS] --node-id <NODE_IDENTIFIER_PREFIX> --object-store <OBJECT_STORE_TYPE>

{}
  --node-id <NODE_ID>              Node identifier used as prefix in object store file paths
                                  [env: INFLUXDB3_NODE_IDENTIFIER_PREFIX=]
  --object-store <STORE>           Object storage to use [default: memory]
                                  [possible values: memory, memory-throttled, file, s3, google, azure]

{}
  --http-bind <ADDR>               Address for HTTP API requests [default: 0.0.0.0:8181]
                                  [env: INFLUXDB3_HTTP_BIND_ADDR=]
  --log-filter <FILTER>            Logs: filter directive [env: LOG_FILTER=]
  --tls-key <KEY_FILE>             The path to the key file for TLS to be enabled
                                  [env: INFLUXDB3_TLS_KEY=]
  --tls-cert <CERT_FILE>           The path to the cert file for TLS to be enabled
                                  [env: INFLUXDB3_TLS_CERT=]
  --tls-minimum-version <VERSION>  The minimum version for TLS. Valid values are
                                   tls-1.2 and tls-1.3, default is tls-1.2
                                  [env: INFLUXDB3_TLS_MINIMUM_VERSION=]
  --without-auth                   Run InfluxDB 3 server without authorization
  --disable-authz <RESOURCES>      Optionally disable authz by passing in a comma separated
                                   list of resources. Valid values are health, ping, and metrics.
                                   To disable auth for multiple resources pass in a list, eg.
                                   `--disable-authz health,ping`

{}
  --data-dir <DIR>                 Location to store files locally [env: INFLUXDB3_DB_DIR=]
  --bucket <BUCKET>                Bucket name for cloud object storage [env: INFLUXDB3_BUCKET=]
  --gen1-duration <DURATION>       Duration for Parquet file arrangement [default: 10m]
                                  [env: INFLUXDB3_GEN1_DURATION=]
  --gen1-lookback-duration <DURATION>
                                   The amount of time that the server looks back on startup
                                   when populating the in-memory index of gen1 files.
                                  [env: INFLUXDB3_GEN1_LOOKBACK_DURATION=]
  --delete-grace-period <DURATION> Grace period for hard deleted databases and tables before they are
                                   removed permanently from the catalog [default: 24h]
                                   [env: INFLUXDB3_DELETE_GRACE_PERIOD=]

{}
  --aws-access-key-id <KEY>        S3 access key ID [env: AWS_ACCESS_KEY_ID=] [default: ]
  --aws-secret-access-key <KEY>    S3 secret access key [env: AWS_SECRET_ACCESS_KEY=] [default: ]
  --aws-default-region <REGION>    S3 region [default: us-east-1] [env: AWS_DEFAULT_REGION=]
  --aws-endpoint <ENDPOINT>        S3 compatibility endpoint [env: AWS_ENDPOINT=]
  --aws-session-token <TOKEN>      S3 session token for federated login/SSO [env: AWS_SESSION_TOKEN=]
  --aws-allow-http                 Allow unencrypted HTTP to AWS [env: AWS_ALLOW_HTTP=]
  --aws-skip-signature             Skip request signing [env: AWS_SKIP_SIGNATURE=]
  --aws-credentials-file <PATH>    S3 credentials file. The format is JSON that looks like the
                                   following:

                                   {{
                                     "aws_access_key_id": "<key>",
                                     "aws_secret_access_key": "<secret>",
                                     "aws_session_token": "<token>",
                                     "expiry": "<expiry_timestamp_seconds_since_epoch>"
                                   }}

                                   Settings in this file override the corresponding CLI flags.

                                   The `aws_session_token` and `expiry` fields are optional and
                                   the file is automatically checked for updates at the expiry
                                   time if specified or at 1-hour intervals.

                                   If the object store returns an "Unauthenticated" error,
                                   InfluxDB3 will attempt to update its in-memory credentials
                                   from this file then retry the object store request.

                                  [env: AWS_CREDENTIALS_FILE]

{}
  --google-service-account <PATH>  Path to Google credentials JSON [env: GOOGLE_SERVICE_ACCOUNT=]

{}
  --azure-storage-account <ACCT>   Azure storage account name [env: AZURE_STORAGE_ACCOUNT=]
  --azure-storage-access-key <KEY> Azure storage access key [env: AZURE_STORAGE_ACCESS_KEY=]

{}
  --plugin-dir <DIR>               Location of plugins [env: INFLUXDB3_PLUGIN_DIR=]
  --virtual-env-location <PATH>    [env: VIRTUAL_ENV=]
  --package-manager <MANAGER>      [default: discover] [possible values: discover, pip, uv]

{}
  --object-store-connection-limit <LIMIT>
                                  Connection limit for network object stores [default: 16]
                                  [env: OBJECT_STORE_CONNECTION_LIMIT=]
  --object-store-http2-only        Force HTTP/2 for object stores [env: OBJECT_STORE_HTTP2_ONLY=]
  --object-store-http2-max-frame-size <SIZE>
                                  HTTP/2 max frame size [env: OBJECT_STORE_HTTP2_MAX_FRAME_SIZE=]
  --object-store-max-retries <N>   Max request retry attempts [env: OBJECT_STORE_MAX_RETRIES=]
  --object-store-retry-timeout <TIMEOUT>
                                  Max retry timeout [env: OBJECT_STORE_RETRY_TIMEOUT=]
  --object-store-cache-endpoint <ENDPOINT>
                                  S3 compatible cache endpoint [env: OBJECT_STORE_CACHE_ENDPOINT=]

{}
  --max-http-request-size <SIZE>   Maximum size of HTTP requests [default: 10485760]
                                  [env: INFLUXDB3_MAX_HTTP_REQUEST_SIZE=]

{}
  --exec-mem-pool-bytes <SIZE>     Memory pool size for query execution [default: 20%]
                                  [env: INFLUXDB3_EXEC_MEM_POOL_BYTES=]
  --parquet-mem-cache-size <SIZE>  In-memory Parquet cache size [default: 20%]
                                  [env: INFLUXDB3_PARQUET_MEM_CACHE_SIZE=]
  --force-snapshot-mem-threshold <THRESH>
                                  Internal buffer threshold [default: 50%]
                                  [env: INFLUXDB3_FORCE_SNAPSHOT_MEM_THRESHOLD=]
  --parquet-mem-cache-prune-percentage <PCT>
                                  Percentage to prune from cache [default: 0.1]
                                  [env: INFLUXDB3_PARQUET_MEM_CACHE_PRUNE_PERCENTAGE=]
  --parquet-mem-cache-prune-interval <INTERVAL>
                                  Cache prune check interval [default: 1s]
                                  [env: INFLUXDB3_PARQUET_MEM_CACHE_PRUNE_INTERVAL=]
  --parquet-mem-cache-query-path-duration <DURATION>
                                  Duration to check for query path caching [default: 5h]
                                  [env: INFLUXDB3_PARQUET_MEM_CACHE_QUERY_PATH_DURATION=]
  --disable-parquet-mem-cache      Disable in-memory Parquet cache [env: INFLUXDB3_DISABLE_PARQUET_MEM_CACHE=]

{}
  --wal-flush-interval <INTERVAL>  Interval to flush data to WAL file [default: 1s]
                                  [env: INFLUXDB3_WAL_FLUSH_INTERVAL=]
  --wal-snapshot-size <SIZE>       Number of WAL files per snapshot [default: 600]
                                  [env: INFLUXDB3_WAL_SNAPSHOT_SIZE=]
  --wal-max-write-buffer-size <SIZE>
                                  Max write requests in buffer [default: 100000]
                                  [env: INFLUXDB3_WAL_MAX_WRITE_BUFFER_SIZE=]
  --wal-replay-concurrency-limit <LIMIT>
                                  Concurrency limit during WAL replay [default: no_limit]
                                  If replay runs into OOM, set this to a lower number eg. 10
                                  [env: INFLUXDB3_WAL_REPLAY_CONCURRENCY_LIMIT=]
  --snapshotted-wal-files-to-keep <N>
                                  Number of snapshotted WAL files to retain [default: 300]
                                  [env: INFLUXDB3_NUM_WAL_FILES_TO_KEEP=]

{}
  --last-cache-eviction-interval <INTERVAL>
                                  Last-N-Value cache eviction interval [default: 10s]
                                  [env: INFLUXDB3_LAST_CACHE_EVICTION_INTERVAL=]
  --distinct-cache-eviction-interval <INTERVAL>
                                  Distinct Value cache eviction interval [default: 10s]
                                  [env: INFLUXDB3_DISTINCT_CACHE_EVICTION_INTERVAL=]
  --query-log-size <SIZE>          Size of the query log [default: 1000]
                                  [env: INFLUXDB3_QUERY_LOG_SIZE=]
  --query-file-limit <LIMIT>       Max parquet files allowed in a query
                                  [env: INFLUXDB3_QUERY_FILE_LIMIT=]

{}
  --datafusion-num-threads <N>     Max DataFusion runtime threads
                                  [env: INFLUXDB3_DATAFUSION_NUM_THREADS=]
  --datafusion-runtime-type <TYPE> DataFusion runtime type [default: multi-thread]
                                  [env: INFLUXDB3_DATAFUSION_RUNTIME_TYPE=]
                                  [possible values: current-thread, multi-thread, multi-thread-alt]
  --datafusion-max-parquet-fanout <N>
                                  Parquet file fanout limit [default: 1000]
                                  [env: INFLUXDB3_DATAFUSION_MAX_PARQUET_FANOUT=]
  --datafusion-use-cached-parquet-loader
                                  Use cached parquet loader
                                  [env: INFLUXDB3_DATAFUSION_USE_CACHED_PARQUET_LOADER=]
  --datafusion-config <CONFIG>     Custom DataFusion configuration [default: ]
                                  [env: INFLUXDB3_DATAFUSION_CONFIG=]
  --datafusion-runtime-disable-lifo-slot <BOOL>
                                  Disable LIFO slot [possible values: true, false]
                                  [env: INFLUXDB3_DATAFUSION_RUNTIME_DISABLE_LIFO_SLOT=]
  --datafusion-runtime-event-interval <N>
                                  Scheduler ticks for polling external events
                                  [env: INFLUXDB3_DATAFUSION_RUNTIME_EVENT_INTERVAL=]
  --datafusion-runtime-global-queue-interval <N>
                                  Scheduler ticks for polling global task queue
                                  [env: INFLUXDB3_DATAFUSION_RUNTIME_GLOBAL_QUEUE_INTERVAL=]
  --datafusion-runtime-max-blocking-threads <N>
                                  Thread limit for DataFusion runtime
                                  [env: INFLUXDB3_DATAFUSION_RUNTIME_MAX_BLOCKING_THREADS=]
  --datafusion-runtime-max-io-events-per-tick <N>
                                  Max events per tick
                                  [env: INFLUXDB3_DATAFUSION_RUNTIME_MAX_IO_EVENTS_PER_TICK=]
  --datafusion-runtime-thread-keep-alive <DURATION>
                                  Blocking pool thread timeout
                                  [env: INFLUXDB3_DATAFUSION_RUNTIME_THREAD_KEEP_ALIVE=]
  --datafusion-runtime-thread-priority <PRIORITY>
                                  Thread priority [default: 10]
                                  [env: INFLUXDB3_DATAFUSION_RUNTIME_THREAD_PRIORITY=]

{}
  --log-destination <DEST>         Logs: destination [default: stdout]
                                  [env: LOG_DESTINATION=]
  --log-format <FORMAT>            Logs: message format [default: full]
                                  [env: LOG_FORMAT=]
  --traces-exporter <TYPE>         Tracing: exporter type [default: none]
                                  [env: TRACES_EXPORTER=]
  --traces-exporter-jaeger-agent-host <HOST>
                                  Jaeger agent hostname [default: 0.0.0.0]
                                  [env: TRACES_EXPORTER_JAEGER_AGENT_HOST=]
  --traces-exporter-jaeger-agent-port <PORT>
                                  Jaeger agent port [default: 6831]
                                  [env: TRACES_EXPORTER_JAEGER_AGENT_PORT=]
  --traces-exporter-jaeger-service-name <NAME>
                                  Jaeger service name [default: iox-conductor]
                                  [env: TRACES_EXPORTER_JAEGER_SERVICE_NAME=]
  --traces-exporter-jaeger-trace-context-header-name <NAME>
                                  Header for trace context [default: uber-trace-id]
                                  [env: TRACES_EXPORTER_JAEGER_TRACE_CONTEXT_HEADER_NAME=]
  --traces-jaeger-debug-name <NAME>
                                  Header for force sampling [default: jaeger-debug-id]
                                  [env: TRACES_EXPORTER_JAEGER_DEBUG_NAME=]
  --traces-jaeger-tags <TAGS>      Key-value pairs for tracing spans
                                  [env: TRACES_EXPORTER_JAEGER_TAGS=]
  --traces-jaeger-max-msgs-per-second <N>
                                  Max messages per second [default: 1000]
                                  [env: TRACES_JAEGER_MAX_MSGS_PER_SECOND=]


{}
  -v, --verbose                    Increase logging verbosity
  -h, --help                       Print help information
  --help-all                       Show all available options

For more help on how to use InfluxDB 3 Core, go to https://docs.influxdata.com/influxdb3/core/
